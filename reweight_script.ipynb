{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# load the student model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "29999"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from celeba_u import make_model, make_dataset\n",
    "from moving_average import init_ema_model\n",
    "from train_utils import *\n",
    "from celeba_dataset import CelebaWrapper\n",
    "\n",
    "class WeightedTrainingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, L, weight):\n",
    "        self.dataset = dataset\n",
    "        self.L = L\n",
    "        self.weight = weight\n",
    "    def __getitem__(self, item):\n",
    "        idx = random.randint(0, len(self.dataset) - 1)\n",
    "        r = self.weight[idx] * self.dataset[idx][0]\n",
    "        return r, 0\n",
    "    def __len__(self):\n",
    "        return self.L\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "train_set = make_dataset()\n",
    "train_len = len(train_set.dataset)\n",
    "weight = torch.ones(train_len)\n",
    "train_dataset = WeightedTrainingDataset(train_set, train_len, weight)\n",
    "len(train_dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num timesteps: 1024, time scale: 1.\n"
     ]
    }
   ],
   "source": [
    "teacher_ema = make_model().to(device)\n",
    "image_size = teacher_ema.image_size\n",
    "ckpt = torch.load('./checkpoints/celeba/original/checkpoint.pt')  # base checkpoint\n",
    "teacher_ema.load_state_dict(ckpt[\"G\"])\n",
    "n_timesteps = ckpt[\"n_timesteps\"]\n",
    "time_scale = ckpt[\"time_scale\"]\n",
    "del ckpt\n",
    "print(f\"Num timesteps: {n_timesteps}, time scale: {time_scale}.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from v_diffusion import *\n",
    "\n",
    "scheduler = StrategyConstantLR()\n",
    "distillation_model = DiffusionDistillation(scheduler)\n",
    "\n",
    "def make_diffusion(model, n_timestep, time_scale, device):\n",
    "    betas = make_beta_schedule(\"cosine\", cosine_s=8e-3, n_timestep=n_timestep).to(device)\n",
    "    sampler = \"ddpm\"\n",
    "    return GaussianDiffusion(model, betas, time_scale=time_scale, sampler=sampler)\n",
    "\n",
    "teacher_ema_diffusion = make_diffusion(teacher_ema, n_timesteps, time_scale, device)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def make_dataset_val():\n",
    "    return CelebaWrapper(dataset_dir=\"./data/celeba_val/\", resolution=256)\n",
    "val_set = make_dataset_val()\n",
    "val_len = len(val_set.dataset)\n",
    "val_dataset = InfinityDataset(val_set, val_len)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "student = make_model().to(device)  # student也是unet的backbone\n",
    "student_ema = make_model().to(device)\n",
    "ckpt = torch.load('./checkpoints/celeba/base_0/checkpoint.pt')  # base checkpoint\n",
    "student.load_state_dict(ckpt[\"G\"])\n",
    "student_ema.load_state_dict(ckpt[\"G\"])\n",
    "del ckpt\n",
    "distill_train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)  # 用的是Trainingset\n",
    "\n",
    "checkpoints_dir = os.path.join(\"checkpoints\", \"celeba\", \"base_0\")\n",
    "tensorboard = SummaryWriter(os.path.join(checkpoints_dir, \"tensorboard\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "student_diffusion = make_diffusion(student, teacher_ema_diffusion.num_timesteps // 2, teacher_ema_diffusion.time_scale * 2, device)  # 实例化student diffusion\n",
    "student_ema_diffusion = make_diffusion(student_ema, teacher_ema_diffusion.num_timesteps // 2, teacher_ema_diffusion.time_scale * 2, device)\n",
    "on_iter = make_iter_callback(student_ema_diffusion, device, checkpoints_dir, image_size, tensorboard, 15, 30, False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distillation_model.reweight_val_student(distill_train_loader, teacher_ema_diffusion, student_diffusion, student_ema, student_lr=0.3 * 5e-5, device=device, make_extra_args=make_condition, on_iter=on_iter)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare the validation dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The val data is saved at ./data/celeba_val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_dataset_val():\n",
    "    return CelebaWrapper(dataset_dir=\"./data/celeba_val/\", resolution=256)\n",
    "\n",
    "\n",
    "\n",
    "val_set = make_dataset_val()\n",
    "val_len = len(val_set.dataset)\n",
    "weight = torch.ones(val_len)\n",
    "val_dataset = InfinityDataset(val_set, val_len, weight)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "checkpoints_dir = os.path.join(\"checkpoints\", \"celeba\", \"base_0\")\n",
    "image_size = unet_model.image_size\n",
    "tensorboard = SummaryWriter(os.path.join(checkpoints_dir, \"tensorboard\"))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=True)\n",
    "on_iter = make_iter_callback(student_diffusion_ema, device, checkpoints_dir, image_size, tensorboard, 15, 30, False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "scheduler = StrategyConstantLR()\n",
    "diffusion_train = DiffusionTrain(scheduler)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "diffusion_train.train(val_loader, student_diffusion, unet_model_ema, model_lr=5e-5, device=device, make_extra_args=make_condition, on_iter=on_iter)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Test for reweight framework"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]], requires_grad=True)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 读取数据集逻辑\n",
    "weight = [1, 1, 1, 1, 1, 1, 1, 1]  # load weight\n",
    "sample, label = torch.randn(4, 10), torch.randn(4, 5)\n",
    "\n",
    "weight = torch.tensor(weight, dtype=torch.float).unsqueeze(1)\n",
    "print(weight)\n",
    "\n",
    "# 转化成可训练参数\n",
    "weight = nn.Parameter(weight)\n",
    "weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "DemoModel(\n  (backbone): Linear(in_features=10, out_features=5, bias=True)\n)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取模型\n",
    "class DemoModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Linear(10, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "model = DemoModel()\n",
    "model.requires_grad_(False)  # 关闭梯度"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.3503, -0.8262,  0.4586,  0.3807, -0.5822],\n        [ 0.0338,  0.5614,  1.1887, -0.1049, -0.0895],\n        [-0.4504,  0.5381,  0.8031, -0.7693,  0.6945],\n        [ 0.5707, -0.0521,  0.2479, -0.2745, -0.1978]],\n       grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 前向传播\n",
    "val_sample, val_label = torch.randn(4, 10), torch.randn(4, 5)\n",
    "out = model(val_sample*weight[4:8])\n",
    "out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# 反向传播\n",
    "loss = torch.sum(torch.square(out-label))\n",
    "loss.backward()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.0000],\n        [ 0.0000],\n        [ 0.0000],\n        [ 0.0000],\n        [ 3.9352],\n        [ 3.7999],\n        [-0.1606],\n        [ 0.5773]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看权重的梯度\n",
    "weight.grad"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.0025],\n        [0.9975],\n        [0.9961],\n        [0.9981]])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 更新权重\n",
    "lr = 0.001\n",
    "new_weight = (weight - lr * weight.grad).detach()\n",
    "new_weight"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "test",
   "language": "python",
   "display_name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
